{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eAXnMj5E9jWG"
   },
   "source": [
    "# Part 3: Asset data dive\n",
    "Let's get started with a guided exploration of the Valhall Platform. In this notebook we will pick one of the equipment that we visualized in operational intelligence and take a closer look at all of the available data!\n",
    "\n",
    "\n",
    "## Quick links\n",
    "* Back to the [Hackathon github repo](https://github.com/cognitedata/open-industrial-data/tree/master/workshops/uni-hackathon)\n",
    "* Documentation of [CDP concepts](https://doc.cognitedata.com/concepts/)\n",
    "* Reference documentation for the [Python SDK](https://cognite-sdk-python.readthedocs-hosted.com/en/latest/)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k8-Oj493ReNU"
   },
   "source": [
    "# Step 0: Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Lf5pnaDBLnc"
   },
   "source": [
    "#### Install the Cognite SDK package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "pbgkP3p59iiK",
    "outputId": "08280aa7-b1f3-4ba1-c5bf-06252ed70958"
   },
   "outputs": [],
   "source": [
    "# if you're working in google colab or similar\n",
    "!pip install -q cognite-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CN5J9FmPBRLk"
   },
   "source": [
    "#### Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uFkQ73a44wmU"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import datetime\n",
    "from getpass import getpass\n",
    "from typing import List, Any\n",
    "from itertools import islice\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from cognite import CogniteClient\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms.traversal.depth_first_search import dfs_tree\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using google colab, you have to run `configure_plotly_browser_state()` in a cell, which creates plotly graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_plotly_browser_state():\n",
    "    import IPython\n",
    "    display(IPython.core.display.HTML('''\n",
    "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "        <script>\n",
    "          requirejs.config({\n",
    "            paths: {\n",
    "              base: '/static/base',\n",
    "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
    "            },\n",
    "          });\n",
    "        </script>\n",
    "        '''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pr0CQECZBWW3"
   },
   "source": [
    "#### Connect to the Cognite Data Platform\n",
    "The SDK client is the entrypoint to all data in CDP, and simply requires the API key that you generated in Part 1.\n",
    "\n",
    "When prompted for your API key, use the key generated by open industrial data as mentioned in the Getting Started steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "E8CdoRFu9n2t",
    "outputId": "d1753b86-0b79-4984-e5e0-750bfaf124db"
   },
   "outputs": [],
   "source": [
    "client = CogniteClient(api_key=getpass(\"Open Industrial Data API-KEY: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VKFPBwYsRjHL"
   },
   "source": [
    "# Step 1: Learn about Organizing Industrial Data\n",
    "\n",
    "The Cognite Data Platform organizes digital information about the physical world. The building blocks of this representation are called *resources*, which you can read up on in detail [here](https://doc.cognitedata.com/concepts/#core-concepts).\n",
    "\n",
    "An important resource to understand is the Asset resource. This is the foundation for organizing industrial data -- time series, work orders, event logs and arbitrary files -- from across complex industrial systems.\n",
    "Assets are linked together with parent-child relationships to build a top-down hierarchical tree, known as \"The Asset Hierarchy\".\n",
    "For example, an Asset Hierarchy could look like this:\n",
    "```\n",
    "  Gas Export Compressor\n",
    "    |- First stage export compressor\n",
    "    |    |- Compressor\n",
    "    |    |- Scrubber\n",
    "    |    |- ...\n",
    "    |- Second stage export compressor\n",
    "    |- ...\n",
    "```\n",
    "Timeseries, events, files and other resources are attached to each Asset.\n",
    "\n",
    "The hierarchical structure can make it easier to find the timeseries data that you're looking for. Though there are [other ways](https://doc.cognitedata.com/concepts/#_3d-models-and-revisions) to do this, we'll focus on using the hierarchy today!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download a sample of assets up to a certain depth in the hierarchy\n",
    "df_sample_assets = client.assets.get_assets(limit=1000, depth=6).to_pandas().sort_values('depth')\n",
    "df_sample_assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it more clear let's visualize our assets hierarchy.\n",
    "There are auxiliary functions for tree plots generation, don't be scared of it :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(seq, n=2):\n",
    "    \"\"\" iterator, which generates a sliding window for `n` elements from a given iterator \"\"\"\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result\n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_assets_tree(df: pd.DataFrame) -> nx.DiGraph:\n",
    "    \"\"\" generates directional graph of assets from a given dataframe \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    for path in df['path'].values:\n",
    "        for parent_id, child_id in sliding_window(path, n=2):\n",
    "            G.add_edge(parent_id, child_id)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchy_pos(G, root=None, width=10000., vert_gap = 0.2, vert_loc = 0, xcenter = 0.5):\n",
    "    '''\n",
    "    If the graph is a tree this will return the positions to plot this in a \n",
    "    hierarchical layout.\n",
    "\n",
    "    G: the graph (must be a tree)\n",
    "\n",
    "    root: the root node of current branch \n",
    "    - if the tree is directed and this is not given, the root will be found and used\n",
    "    - if the tree is directed and this is given, then the positions will be just for the descendants of this node.\n",
    "    - if the tree is undirected and not given, then a random choice will be used.\n",
    "\n",
    "    width: horizontal space allocated for this branch - avoids overlap with other branches\n",
    "\n",
    "    vert_gap: gap between levels of hierarchy\n",
    "\n",
    "    vert_loc: vertical location of root\n",
    "\n",
    "    xcenter: horizontal location of root\n",
    "    '''\n",
    "    if not nx.is_tree(G):\n",
    "        raise TypeError('cannot use hierarchy_pos on a graph that is not a tree')\n",
    "\n",
    "    def _hierarchy_pos(G, root, width=1., vert_gap = 0.2, vert_loc = 0, xcenter = 0.5, pos = None, parent = None):\n",
    "        '''\n",
    "        see hierarchy_pos docstring for most arguments\n",
    "\n",
    "        pos: a dict saying where all nodes go if they have been assigned\n",
    "        parent: parent of this branch. - only affects it if non-directed\n",
    "\n",
    "        '''\n",
    "\n",
    "        if pos is None:\n",
    "            pos = {root:(xcenter,vert_loc)}\n",
    "        else:\n",
    "            pos[root] = (xcenter, vert_loc)\n",
    "        children = list(G.neighbors(root))\n",
    "        if not isinstance(G, nx.DiGraph) and parent is not None:\n",
    "            children.remove(parent)  \n",
    "        if len(children)!=0:\n",
    "            dx = width/len(children) \n",
    "            nextx = xcenter - width/2 - dx/2\n",
    "            for child in children:\n",
    "                nextx += dx\n",
    "                pos = _hierarchy_pos(G,child, width = dx, vert_gap = vert_gap, \n",
    "                                    vert_loc = vert_loc-vert_gap, xcenter=nextx,\n",
    "                                    pos=pos, parent = root)\n",
    "        return pos\n",
    "\n",
    "\n",
    "    return _hierarchy_pos(G, root, width, vert_gap, vert_loc, xcenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(id_):\n",
    "    \"\"\" Get asset's name by given asset id \"\"\"\n",
    "    asset_info = client.assets.get_asset(id_)\n",
    "    return asset_info.to_json()['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_assets_tree_plot(df: pd.DataFrame, root_id: int=None, max_depth: int=None) -> go.Figure:\n",
    "    assets_tree = make_assets_tree(df_sample_assets)\n",
    "    \n",
    "    if root_id is None:\n",
    "        root_id = next(iter(nx.topological_sort(assets_tree)))  #allows back compatibility with nx version 1.11\n",
    "    \n",
    "    assets_tree = dfs_tree(assets_tree, source=root_id, depth_limit=max_depth)\n",
    "    pos = hierarchy_pos(assets_tree, root=root_id)\n",
    "    \n",
    "    # extract node coordinates and labels\n",
    "    Xn = [pos[i][0] for i in pos.keys()]\n",
    "    Yn = [pos[i][1] for i in pos.keys()]\n",
    "    labels = [get_label(id_) for id_ in pos.keys()]\n",
    "    \n",
    "    # extract edges from tree\n",
    "    Xe = list()\n",
    "    Ye = list()\n",
    "    for e in assets_tree.edges():\n",
    "        Xe.extend([pos[e[0]][0], pos[e[1]][0], None])\n",
    "        Ye.extend([pos[e[0]][1], pos[e[1]][1], None])\n",
    "    \n",
    "    # make plotly traces\n",
    "    trace_nodes=dict(\n",
    "      type='scatter',\n",
    "      x=Xn, \n",
    "      y=Yn,\n",
    "      mode='markers',\n",
    "      marker=dict(size=20, color='rgb(0, 0, 204)'),\n",
    "      text=labels,\n",
    "      hoverinfo='text'\n",
    "    )\n",
    "    trace_edges=dict(\n",
    "      type='scatter',\n",
    "      mode='lines',\n",
    "      x=Xe,\n",
    "      y=Ye,\n",
    "      line=dict(width=1, color='rgb(25,25,25)'),\n",
    "      hoverinfo='none' \n",
    "    )\n",
    "    \n",
    "    # some pretty details\n",
    "    axis=dict(\n",
    "        showline=False, # hide axis line, grid, ticklabels and  title\n",
    "        zeroline=False,\n",
    "        showgrid=False,\n",
    "        showticklabels=False,\n",
    "        title='' \n",
    "    )\n",
    "    layout = go.Layout(\n",
    "      autosize=True,\n",
    "      showlegend=False,\n",
    "      xaxis=axis,\n",
    "      yaxis=axis,\n",
    "      hovermode='closest',\n",
    "    )\n",
    "    \n",
    "    fig = go.Figure(data=[trace_edges, trace_nodes], layout=layout)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configure_plotly_browser_state()\n",
    "\n",
    "fig = make_assets_tree_plot(df_sample_assets)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may found this overcomplicated, but if you wanna explore your assets in interactive way - that's a good way. Also, you can play with `root_id` and `max_depth` arguments for `make_assets_tree_plot()` function, and build only a branch in details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_assets = client.assets.get_assets(limit=2000, depth=15).to_pandas().sort_values('depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "configure_plotly_browser_state()\n",
    "\n",
    "fig = make_assets_tree_plot(df_sample_assets, root_id=4518112062673878, max_depth=4)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Pick an asset for further investigation\n",
    "For the rest of the workshop, you'll be working with one of the subsystems that you visualized in the [LIVE Operational Intelligence System Overview](https://opint.cogniteapp.com/publicdata/infographics/-LOHKEJPLvt0eRIZu8mE) (see below).\n",
    "Either pick an asset yourself below, or let fate decide ;)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "SYSTEM_OVERVIEW_ASSETS = [\n",
    "    '23-ESDV-92501A',\n",
    "    '23-ESDV-92501B',\n",
    "    '23-HA-9103',\n",
    "    '23-PV-92538',\n",
    "    '23-VG-9101',\n",
    "    '23-KA-9101',\n",
    "    '23-HA-9115',\n",
    "    '23-HA-9114',\n",
    "    '23-FV-92543',\n",
    "    '23-ESDV-92551A',\n",
    "    '23-ESDV-92551B',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the asset metadata from CDP using the assets client\n",
    "\n",
    "df_system_overview_assets = pd.concat([\n",
    "    client.assets.get_assets(name=n).to_pandas()\n",
    "    for n in SYSTEM_OVERVIEW_ASSETS\n",
    "])[['name', 'id', 'parentId', 'description']].set_index('name')\n",
    "\n",
    "df_system_overview_assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an asset for analysis, or let fate decide :)\n",
    "\n",
    "asset_name = random.choice(SYSTEM_OVERVIEW_ASSETS)\n",
    "\n",
    "asset_id = df_system_overview_assets.loc[asset_name, 'id']\n",
    "\n",
    "print(\"And my asset is!\")\n",
    "df_system_overview_assets.loc[asset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Find all the timeseries for your asset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X75GOITO_m1q"
   },
   "source": [
    "The interface `client.assets.get_asset_subtree()` can be used to retrieve all of the *children* of an Asset. The `depth` parameter sets how far we traverse down the hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "1OPecRPv6xsU",
    "outputId": "1b282255-fb8a-412b-a30c-4a4c096d1719"
   },
   "outputs": [],
   "source": [
    "df_asset_children = client.assets.get_asset_subtree(\n",
    "    asset_id=df_system_overview_assets.loc[asset_name, 'id'],\n",
    "    depth=10\n",
    ").to_pandas().sort_values('depth')\n",
    "df_asset_children[['depth', 'id', 'parentId', 'description']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... Assets are interesting to see how things are put together, but what I'm sure you're really after are those petabytes of **time series**; those beautiful pressure (PT), temperature (TT) and flow (TT) sensors that have recorded the life of the platform for the last few years.\n",
    "\n",
    "First we need to find all these time series. We can use the `path` parameter in the `time_series` client to get all the time series attached to assets below our system overview asset. Note that this parameter maps directly to the CDP API, and therefore needs to provide the asset id formatted carefully as a json string: `\"[id, ]\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asset_children_timeseries = client.time_series.get_time_series(path=str([asset_id])).to_pandas()\n",
    "df_asset_children_timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have discovered the timeseries below our asset!\n",
    "\n",
    "**Note**: CDP can also store string and step timeseries. Step timeseries have different aggregation methods, and support dead-band-compression for time series that do not change very often (e.g. valve opening angles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Into the timeseries datapoints!\n",
    "In CDP we do some very clever things in the backend to store serve up timeseries just the way you like it:\n",
    "- Store the timeseries (timestamp, value) in their raw format, because one day we'll need it\n",
    "- Precompute aggregations for millisecond response times\n",
    "- Build tabular structures server side\n",
    "- Enable natural language time specifications (e.g. `start='8d-ago'` and `granularity='10m'`)\n",
    "\n",
    "So once you've located the timeseries you're interested in analyzing, the `datapoints` client has several options for downloading the data.\n",
    "\n",
    "**Note:** The timeseries column is represented throughout CDP as milliseconds since epoch time. Pandas offers an easy conversion to python datetime with `pd.to_datetime(<column/value>, unit='ms')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set aside string time series for now because they do not aggregate together with numerical time series\n",
    "# consider investigating the string timeseries in part 4b\n",
    "lst_timeseries = df_asset_children_timeseries[~df_asset_children_timeseries['isString']]['name'].tolist()\n",
    "lst_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = client.datapoints.get_datapoints_frame(\n",
    "    time_series=lst_timeseries,\n",
    "    aggregates=['avg'],\n",
    "    granularity='1h',\n",
    "    start='30d-ago',\n",
    ")\n",
    "\n",
    "df_data = df_data.set_index(pd.to_datetime(df_data['timestamp'], unit='ms')).drop('timestamp', axis=1)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot up to 10 random rows\n",
    "df_plot_sample = df_data[random.sample(list(df_data.columns), min(10, len(df_data.columns)))]\n",
    "\n",
    "df_plot_sample.plot(subplots=True, figsize=(20,20));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d21kj8CWNpNN"
   },
   "source": [
    "# Congratulations, you are done with part 3!\n",
    "\n",
    "Save your notebook, and remember your asset for the next part, where we dig deeper into the data."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Part 3 - Asset data dive.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
